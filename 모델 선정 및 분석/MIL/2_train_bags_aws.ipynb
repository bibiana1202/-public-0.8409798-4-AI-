{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgwO4kSs4mEz"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/rosasalberto/mil.git\n",
        "!pip install mil\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0i7WJft4mE2",
        "outputId": "e9756d27-7383-4551-d4ba-2f4f74eef4e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-07 03:36:23.174604: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-07 03:36:24.095976: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-07 03:36:25.773390: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
            "2022-11-07 03:36:25.773543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:\n",
            "2022-11-07 03:36:25.773550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No62Na9X4mE4"
      },
      "outputs": [],
      "source": [
        "FOLDER_NAME = 'ScoreTiler_128_200_10'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlXSSG1X4mE4"
      },
      "outputs": [],
      "source": [
        "x_train1 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train1.npz', allow_pickle=True)\n",
        "\n",
        "x_train2 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train2.npz', allow_pickle=True)\n",
        "\n",
        "x_train3 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train3.npz', allow_pickle=True)\n",
        "x_train4 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train4.npz', allow_pickle=True)\n",
        "x_train5 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train5.npz', allow_pickle=True)\n",
        "x_train6 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train6.npz', allow_pickle=True)\n",
        "x_train7 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train7.npz', allow_pickle=True)\n",
        "x_train7 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train7.npz', allow_pickle=True)\n",
        "x_train8 = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_train8.npz', allow_pickle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTZEUBia4mE5"
      },
      "outputs": [],
      "source": [
        "y_train = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_y_train.npz', allow_pickle=True) \n",
        "\n",
        "y_valid= np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_y_valid.npz', allow_pickle=True)\n",
        "x_valid = np.load(fr'/home/ubuntu/MIL/{FOLDER_NAME}/breast_bags_{FOLDER_NAME}_x_valid.npz', allow_pickle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6sXO1r24mE5"
      },
      "outputs": [],
      "source": [
        "#len(x_train1),len(x_train2)#,len(x_train3),len(x_train4),len(x_train5),len(x_train6),len(x_train7),len(y_train),len(x_valid),len(y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJO8FJdZ4mE6",
        "outputId": "07e9647b-a673-4de8-c21e-81afadd3024f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_train['y']) # 800개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV1OAm9E4mE7",
        "outputId": "8ee7524e-caa7-4ad7-bf9c-b4ecf45ebd24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x_valid['x']) # 200개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg_V1XGM4mE9",
        "outputId": "77a3f3d5-c7c9-45c8-a00f-0dfd536ec3fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_valid['y']) # 200개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dltCteg_4mE-",
        "outputId": "16a67d4d-6e6e-4443-d2a4-6a3eae252af4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x1 = x_train1['x']\n",
        "print(len(x1),type(x1))\n",
        "del x_train1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8k83Afs4mE-",
        "outputId": "24f57b23-927b-4699-cf31-c2a90c0341c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x2 = x_train2['x']\n",
        "print(len(x2),type(x2))\n",
        "del x_train2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYrCg6iW4mE_",
        "outputId": "ba85e766-4035-49a1-bdb6-3bfe79e1dfc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x3 = x_train3['x']\n",
        "print(len(x3),type(x3))\n",
        "del x_train3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWlvQ5BH4mE_",
        "outputId": "22a7f900-0f6c-4111-be69-a5a21cf5f486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x4 = x_train4['x']\n",
        "print(len(x4),type(x4))\n",
        "del x_train4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHeWtLB14mFA",
        "outputId": "5f40a061-962c-4cf7-a86f-6817880172b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x5 = x_train5['x']\n",
        "print(len(x5),type(x5))\n",
        "del x_train5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaF88HPT4mFA",
        "outputId": "68220756-a15a-4fcd-99ba-44ead8c8d3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x6 = x_train6['x']\n",
        "print(len(x6),type(x6))\n",
        "del x_train6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxRHbiCG4mFA",
        "outputId": "d0f6234f-c9a7-4257-82c8-18b3515e9b9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x7 = x_train7['x']\n",
        "print(len(x7),type(x7))\n",
        "del x_train7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2bZ_l5w4mFB",
        "outputId": "d51aed3f-eec2-4d21-9de1-867495902c8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "x8 = x_train8['x']\n",
        "print(len(x8),type(x8))\n",
        "del x_train8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-r6wfeuE4mFB"
      },
      "outputs": [],
      "source": [
        "bags_train = np.concatenate((x1,x2,x3,x4,x5,x6,x7,x8), axis=0)\n",
        "del x1,x2,x3,x4,x5,x6,x7,x8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2cOCIqP4mFB",
        "outputId": "8ebf9faf-bcc7-405a-ce56-708eb62ae828"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(800, numpy.ndarray)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(bags_train),type(bags_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKLh9H6e4mFB",
        "outputId": "e035d436-c245-4c9d-f09f-32bf451b4870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(800, numpy.ndarray)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train = y_train['y'] # 800개\n",
        "len(y_train),type(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3mVb5t34mFB",
        "outputId": "c5bc47b7-bea5-45e8-de41-258401f7af73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200, numpy.ndarray)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_valid = x_valid['x'] # 200개\n",
        "len(x_valid),type(x_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLUqns8p4mFC",
        "outputId": "543417e6-3c41-4e71-99df-7a514a724722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "bags_test = x_valid\n",
        "print(len(bags_test),type(bags_test))\n",
        "del x_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f4JiXpR4mFC",
        "outputId": "f987826e-ff22-4ae9-bb25-74557e416660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "y_test = y_valid['y'] # 200개\n",
        "print(len(y_test),type(y_test))\n",
        "del y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJjk_gWe4mFC",
        "outputId": "b6b3fe69-666c-47a1-832a-07cd28c723a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "800 <class 'numpy.ndarray'>\n",
            "800 <class 'numpy.ndarray'>\n",
            "200 <class 'numpy.ndarray'>\n",
            "200 <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(len(bags_train),type(bags_train))\n",
        "print(len(y_train),type(y_train))\n",
        "print(len(bags_test),type(bags_test))\n",
        "print(len(y_test),type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EH4X1-P74mFC",
        "outputId": "37208349-2e14-4aba-a3a1-a7136f3969f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# maximum  number of instances in the training set\n",
        "max_len_train = np.max([len(bag) for bag in bags_train])\n",
        "max_len_test = np.max([len(bag) for bag in bags_test])\n",
        "\n",
        "max_ = np.max([max_len_train, max_len_test])\n",
        "max_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm23Inb44mFC"
      },
      "outputs": [],
      "source": [
        "bags_train_1D =[np.array(bag).reshape(-1, 128*128) for bag in bags_train]\n",
        "bags_test_1D =[np.array(bag).reshape(-1, 128*128) for bag in bags_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqF6C7Yo4mFD",
        "outputId": "7904500d-5d14-4a98-e07c-aae0142f3938"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(bags_train_1D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTz0lIrG4mFD"
      },
      "source": [
        "# Train DeepAttentionMIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66kRwwhi4mFH"
      },
      "outputs": [],
      "source": [
        "from mil.metrics import AUC, BinaryAccuracy\n",
        "from mil.validators import KFold\n",
        "from mil.trainer.trainer import Trainer\n",
        "from mil.models import SVC\n",
        "from mil.bag_representation.mapping import DiscriminativeMapping\n",
        "from mil.preprocessing import StandarizerBagsList, NormalizeBagsImage\n",
        "\n",
        "from mil.models.bag_level.deep_attention import AttentionDeepPoolingMil\n",
        "from mil.utils.utils import get_samples_weight\n",
        "from mil.utils.padding import Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFRIw-Xc4mFH",
        "outputId": "83d37ee0-9cc9-49b3-b78e-3f547aeaaa07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-07 03:39:12.271837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:12.400069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:12.400283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:12.402634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-07 03:39:12.403032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:12.403211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:12.403373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:13.795032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:13.796339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:13.796518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-07 03:39:13.796647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20768 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer()\n",
        "\n",
        "metrics = [AUC, BinaryAccuracy]\n",
        "model = AttentionDeepPoolingMil(gated=False, threshold=0.4)\n",
        "pipeline = [('padding', Padding(max_len=max_))]\n",
        "\n",
        "trainer.prepare(model, preprocess_pipeline=pipeline ,metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nayzyLTD4mFI",
        "outputId": "9fd00a18-dc32-4c2f-b222-4e1cd2d44b22"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
          ]
        }
      ],
      "source": [
        "valid = KFold(n_splits=2, shuffle=True)\n",
        "\n",
        "history = trainer.fit(bags_train_1D[:], y_train[:], validation_strategy=valid, sample_weights='balanced',verbose=1, model__epochs=100, model__batch_size=1, model__verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b-Nj43t4mFI",
        "outputId": "12b203a6-f696-4341-bc10-ce6543f5b347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.528\n",
            "0.5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'auc': 0.5, 'binaryaccuracy': 0.5}, {'auc': 0.5, 'binaryaccuracy': 0.556}]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(np.mean([e['binaryaccuracy'] for e in history['metrics_val']]))\n",
        "print(np.mean([e['auc'] for e in history['metrics_val']]))\n",
        "history['metrics_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0Ypbb8X4mFI",
        "outputId": "671b8fbb-77e1-4891-8a66-c080abb6469e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 1s 112ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'auc': 0.5, 'binaryaccuracy': 0.475}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.predict_metrics(bags_test_1D, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngRo-1K04mFJ",
        "outputId": "7547cca8-9588-4242-c264-29bcfc347c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 2s 192ms/step\n"
          ]
        }
      ],
      "source": [
        "# positive instances with more than 0.4 in attention weight\n",
        "pos = trainer.get_positive_instances(bags_test_1D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HsawA8z4mFJ",
        "outputId": "b0f73f64-8200-46bb-845b-f0345a6bf2ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 1s 165ms/step\n"
          ]
        }
      ],
      "source": [
        "# getting the attention weights for each bag\n",
        "_, att = trainer.model.model(trainer.pipeline[:-1].transform(bags_test_1D))\n",
        "att = att.numpy().reshape([len(bags_test_1D), -1])\n",
        "\n",
        "# getting the prediction of the bag\n",
        "y_pred = trainer.predict(bags_test_1D)\n",
        "y_pred = y_pred.reshape([len(bags_test_1D), -1])\n",
        "y_pred = np.where(y_pred >= 0.5, 1, 0).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WDYpPAk4mFJ",
        "outputId": "3d7b4faa-11a7-4e3f-965b-0757b5fd8b8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbmnHPI84mFJ"
      },
      "outputs": [],
      "source": [
        "\"\"\"model.save(r'C:\\A\\breastCancer\\mil\\output/model_AttentionDeepPoolingMil_1.h5')\n",
        "\n",
        "import pickle\n",
        "with open(r'C:\\A\\breastCancer\\mil\\output/history_AttentionDeepPoolingMil_1.pickle','wb') as g:\n",
        "    pickle.dump(history,g,pickle.HIGHEST_PROTOCOL)\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LFvKUTe4mFK"
      },
      "source": [
        "### Ploting attention weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OW_k_D44mFK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def add_subplot_border(ax, width=4, color=None):\n",
        "    fig = ax.get_figure()\n",
        "    # Convert bottom-left and top-right to display coordinates\n",
        "    x0, y0 = ax.transAxes.transform((0, 0))\n",
        "    x1, y1 = ax.transAxes.transform((1, 1))\n",
        "\n",
        "    # Convert back to Axes coordinates\n",
        "    x0, y0 = ax.transAxes.inverted().transform((x0, y0))\n",
        "    x1, y1 = ax.transAxes.inverted().transform((x1, y1))\n",
        "\n",
        "    rect = plt.Rectangle(\n",
        "        (x0, y0), x1-x0, y1-y0,\n",
        "        color=color,\n",
        "        transform=ax.transAxes,\n",
        "        zorder=-1,\n",
        "        lw=2*width+1,\n",
        "        fill=None,\n",
        "    )\n",
        "    fig.patches.append(rect)\n",
        "\n",
        "def plot_bag(bag, label_bag, label_prediction, label_instance, attention, threshold, digit):\n",
        "    fig, ax = plt.subplots(1,len(bag),figsize=(20,2.5))\n",
        "    for i in range(len(bag)):\n",
        "        #plotting images\n",
        "        ax[i].axis('off')\n",
        "        if label_instance[i] in digit and label_bag == 1:\n",
        "            img_plot = ax[i].imshow(np.abs(bag[i]*255-255), cmap='gray', vmin=0, vmax=255)\n",
        "        else:\n",
        "            img_plot = ax[i].imshow(bag[i]*255, cmap='gray', vmin=0, vmax=255)\n",
        "        ax[i].set_title(str(label_instance[i]))\n",
        "        ax[i].text(0.5,-0.15, str(round(attention[i], 3)), size=12, ha=\"center\", \n",
        "         transform=ax[i].transAxes)\n",
        "        \n",
        "        # contour selected image\n",
        "        if attention[i] > threshold and label_prediction==1:\n",
        "            add_subplot_border(ax[i], color='r')\n",
        "        \n",
        "    \n",
        "    fig.suptitle(\"Bag label: {}, Bag prediction: {}\".format(label_bag, label_prediction))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMDff6R84mFK",
        "outputId": "f69a4814-e4b4-4868-90f3-4e866fb1a02a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_ins' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\A\\breastCancer\\mil\\examples\\trainer\\1_train_mnist_bags.ipynb 셀 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/A/breastCancer/mil/examples/trainer/1_train_mnist_bags.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/A/breastCancer/mil/examples/trainer/1_train_mnist_bags.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     plot_bag(bags_test[i], y_test[i], y_pred[i], test_ins[i], att[i], threshold\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, digit\u001b[39m=\u001b[39m[\u001b[39m7\u001b[39m])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'test_ins' is not defined"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    plot_bag(bags_test[i], y_test[i], y_pred[i], test_ins[i], att[i], threshold=0.5, digit=[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLNoLFcA4mFK",
        "outputId": "9a829942-1a44-409d-e128-2b6b65e42546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([0, 2, 3, 7, 8, 9], dtype=uint8), array([ 1,  2,  1, 64,  2,  2], dtype=int64))\n"
          ]
        }
      ],
      "source": [
        "true_label = []\n",
        "for pos_ins in pos:\n",
        "    true_label.append(test_ins[pos_ins[0]][pos_ins[1]])\n",
        "y_pred = np.array(true_label)\n",
        "\n",
        "# detected as positive instances\n",
        "print(np.unique(y_pred, return_counts=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkWxr3e84mFK"
      },
      "source": [
        "# Train APR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DfKPxVN4mFK"
      },
      "outputs": [],
      "source": [
        "from mil.models import APR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbsAnrry4mFL"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer()\n",
        "\n",
        "metrics = [AUC, BinaryAccuracy]\n",
        "model = APR(thres=0.1, epsilon=0.38, step=200, verbose=0)\n",
        "pipeline = []\n",
        "\n",
        "trainer.prepare(model, preprocess_pipeline=pipeline ,metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9-9IxXX4mFL"
      },
      "outputs": [],
      "source": [
        "valid = KFold(n_splits=2, shuffle=True)\n",
        "\n",
        "history = trainer.fit(bags_train_1D[:100], y_train[:100], validation_strategy=valid, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGyMU5Rw4mFL",
        "outputId": "4cea6f71-fcbd-466f-8dbd-ec864984354f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5575\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'auc': 0.4965278, 'binaryaccuracy': 0.55},\n",
              " {'auc': 0.5203993, 'binaryaccuracy': 0.565}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(np.mean([e['binaryaccuracy'] for e in history['metrics_val']]))\n",
        "history['metrics_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ik6J4Eo4mFL"
      },
      "outputs": [],
      "source": [
        "model.save(r'C:\\A\\breastCancer\\mil\\output/model_APR_1.h5')\n",
        "\n",
        "import pickle\n",
        "with open(r'C:\\A\\breastCancer\\mil\\output/history_APR_1.pickle','wb') as g:\n",
        "    pickle.dump(history,g,pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTbZGeK34mFL"
      },
      "source": [
        "### Plotting the most discriminative features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlD-mhPu4mFL",
        "outputId": "d0c90524-6e14-42a4-b633-77eaa4889765"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAALTklEQVR4nO3dQaxc5XnG8f9TkmwIUk0RlktISSt2WZAKsSmq6CIRZWOySBVWjlLJWZQq3QWliyBFkaKqTZeVHAXFrVKiSEBBqGqCUBSyijCIgomVQCMncWzZQm5VskoDbxf3GF3MvXfGc2bmzL3v/yeNZubcuXNejnnu933nmzNfqgpJB9/vTF2ApPUw7FIThl1qwrBLTRh2qYn3rXNnSTz1L61YVWWn7aNa9iT3JvlJkteTPDTmvSStVhadZ09yHfBT4OPAOeB54IGq+vEev2PLLq3YKlr2u4DXq+pnVfUb4NvA0RHvJ2mFxoT9FuCX256fG7a9S5LjSU4lOTViX5JGGnOCbqeuwnu66VV1AjgBduOlKY1p2c8Bt257/iHg/LhyJK3KmLA/D9ye5CNJPgB8GnhqOWVJWraFu/FV9dskDwLfBa4DHqmqV5dWmaSlWnjqbaGdOWaXVm4lH6qRtH8YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9TEWpdsPqhmfUNvsuOXfa7FJtc2pY7HxZZdasKwS00YdqkJwy41YdilJgy71IRhl5pwnn0Jpp6T3WvOeGxtB3U+er/WPcaosCc5C7wJvAX8tqruXEZRkpZvGS37n1XVG0t4H0kr5JhdamJs2Av4XpIXkhzf6QVJjic5leTUyH1JGiGzTsDs+cvJ71fV+SQ3A88Af11Vz+3x+sV3pl15gk7bVdWO/yijWvaqOj/cXwKeAO4a836SVmfhsCe5PskNVx4DnwBOL6swScs15mz8YeCJoRv3PuBfq+o/llKVNobd9INj1Jj9mnfmmH0lVjlm1/6zkjG7pP3DsEtNGHapCcMuNWHYpSa8xPUA8Iy75mHLLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNOM9+wK36m2b8Jpv9w5ZdasKwS00YdqkJwy41YdilJgy71IRhl5pwnn0DrPIbflc9z+08+v5hyy41YdilJgy71IRhl5ow7FIThl1qwrBLTTjPvgH281x11+vZ9+N/98yWPckjSS4lOb1t241Jnkny2nB/aLVlShprnm78N4F7r9r2EPBsVd0OPDs8l7TBZoa9qp4DLl+1+Shwcnh8Erh/yXVJWrJFx+yHq+oCQFVdSHLzbi9Mchw4vuB+JC3Jyk/QVdUJ4ARAktVd8SFpT4tOvV1McgRguL+0vJIkrcKiYX8KODY8PgY8uZxyJK1K5pgvfBS4B7gJuAh8Cfg34DvAh4FfAJ+qqqtP4u30XnbjpRWrqh0n+WeGfZkMu7R6u4Xdj8tKTRh2qQnDLjVh2KUmDLvUhJe4HgB7zahs4qWWmoYtu9SEYZeaMOxSE4ZdasKwS00YdqkJwy414Tz7AeBcuuZhyy41YdilJgy71IRhl5ow7FIThl1qwrBLTTjPrn1rPy6bPCVbdqkJwy41YdilJgy71IRhl5ow7FIThl1qwnl27VvOo1+bmS17kkeSXEpyetu2h5P8KslLw+2+1ZYpaax5uvHfBO7dYfs/VtUdw+3fl1uWpGWbGfaqeg64vIZaJK3QmBN0DyZ5eejmH9rtRUmOJzmV5NSIfUkaKbMuJgBIchvwdFV9dHh+GHgDKODLwJGq+uwc7zN7Z5JGqaodz1wu1LJX1cWqequq3ga+Dtw1pjhJq7dQ2JMc2fb0k8Dp3V4raTPMnGdP8ihwD3BTknPAl4B7ktzBVjf+LPC5Fda48cZeV+112VqHucbsS9vZAR2zG3ZtkqWO2SXtP4ZdasKwS00YdqkJwy414SWuSzD2bLln23c2dqbI4/putuxSE4ZdasKwS00YdqkJwy41YdilJgy71ITz7NpYzpMvly271IRhl5ow7FIThl1qwrBLTRh2qQnDLjXhPPuc9rq22vlg7Qe27FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhPPsc1rlXLqruGodZrbsSW5N8v0kZ5K8muTzw/YbkzyT5LXh/tDqy5W0qJnrsyc5AhypqheT3AC8ANwPfAa4XFVfTfIQcKiqvjDjvQ7k+uxj2bJrmRZen72qLlTVi8PjN4EzwC3AUeDk8LKTbP0BkLShrmnMnuQ24GPAj4DDVXUBtv4gJLl5l985DhwfV6aksWZ24995YfJB4AfAV6rq8ST/U1W/u+3n/11Ve47b7cbvzG68lmnhbjxAkvcDjwHfqqrHh80Xh/H8lXH9pWUUKmk15jkbH+AbwJmq+tq2Hz0FHBseHwOeXH55PSTZ89ZVVe1507WZ52z83cAPgVeAt4fNX2Rr3P4d4MPAL4BPVdXlGe/lv5Dm5vBmMbt14+cesy+DYde1MOyLGTVml7T/GXapCcMuNWHYpSYMu9SEl7gecPv5jPYm17Yf2bJLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhPOsx8ALietediyS00YdqkJwy41YdilJgy71IRhl5ow7FITzrMfAM6lax627FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUxDzrs9+a5PtJziR5Ncnnh+0PJ/lVkpeG232rL1c7GbOG+dg10F1Dff+YZ332I8CRqnoxyQ3AC8D9wF8Av66qv597Zy7ZvBJjvrxi7CIS+3kRioNqtyWbZ36CrqouABeGx28mOQPcstzyJK3aNY3Zk9wGfAz40bDpwSQvJ3kkyaFdfud4klNJTo2qVNIoM7vx77ww+SDwA+ArVfV4ksPAG0ABX2arq//ZGe9hN34F7MZru9268XOFPcn7gaeB71bV13b4+W3A01X10RnvY9hXwLBru93CPs/Z+ADfAM5sD/pw4u6KTwKnxxYpaXXmORt/N/BD4BXg7WHzF4EHgDvY6safBT43nMzb671s2aUVG9WNXxbDLq3ewt14SQeDYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qYl1L9n8BvDzbc9vGrZtok2tbVPrAmtb1DJr+4PdfrDW69nfs/PkVFXdOVkBe9jU2ja1LrC2Ra2rNrvxUhOGXWpi6rCfmHj/e9nU2ja1LrC2Ra2ltknH7JLWZ+qWXdKaGHapiUnCnuTeJD9J8nqSh6aoYTdJziZ5ZViGetL16YY19C4lOb1t241Jnkny2nC/4xp7E9W2Ect477HM+KTHburlz9c+Zk9yHfBT4OPAOeB54IGq+vFaC9lFkrPAnVU1+Qcwkvwp8Gvgn68srZXk74DLVfXV4Q/loar6wobU9jDXuIz3imrbbZnxzzDhsVvm8ueLmKJlvwt4vap+VlW/Ab4NHJ2gjo1XVc8Bl6/afBQ4OTw+ydb/LGu3S20boaouVNWLw+M3gSvLjE967Paoay2mCPstwC+3PT/HZq33XsD3kryQ5PjUxezg8JVltob7myeu52ozl/Fep6uWGd+YY7fI8udjTRH2nZam2aT5vz+pqj8G/hz4q6G7qvn8E/BHbK0BeAH4hymLGZYZfwz4m6r63ylr2W6HutZy3KYI+zng1m3PPwScn6COHVXV+eH+EvAEW8OOTXLxygq6w/2liet5R1VdrKq3qupt4OtMeOyGZcYfA75VVY8Pmyc/djvVta7jNkXYnwduT/KRJB8APg08NUEd75Hk+uHECUmuBz7B5i1F/RRwbHh8DHhywlreZVOW8d5tmXEmPnaTL39eVWu/AfexdUb+v4C/naKGXer6Q+A/h9urU9cGPMpWt+7/2OoR/SXwe8CzwGvD/Y0bVNu/sLW098tsBevIRLXdzdbQ8GXgpeF239THbo+61nLc/Lis1ISfoJOaMOxSE4ZdasKwS00YdqkJwy41YdilJv4fimk719yGLisAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# most discriminative features\n",
        "disc_features = trainer.model.rel_features_\n",
        "\n",
        "test_im = np.zeros(shape=(28*28,))\n",
        "test_im[disc_features] = 255\n",
        "test_im = test_im.reshape(28,28)\n",
        "\n",
        "plt.imshow(test_im, cmap='gray', vmin=0, vmax=255)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMyou0Qb4mFL",
        "outputId": "89fb6648-5a7f-472f-d6b3-d40544b9b38a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'auc': 0.5714286, 'binaryaccuracy': 0.64}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.predict_metrics(bags_test_1D, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMt9YUN94mFM",
        "outputId": "8acd431b-2394-405f-92a0-3710aa03bb0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([ 1, 74,  1,  2,  6, 10,  2,  7,  8,  3], dtype=int64))\n"
          ]
        }
      ],
      "source": [
        "# predicting positive instances\n",
        "pos = trainer.get_positive_instances(bags_test_1D)\n",
        "\n",
        "true_label = []\n",
        "for pos_ins in pos:\n",
        "    true_label.append(test_ins[pos_ins[0]][pos_ins[1]])\n",
        "y_pred = np.array(true_label)\n",
        "\n",
        "# detected as positive instances\n",
        "print(np.unique(y_pred, return_counts=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OODn_3Qx4mFM"
      },
      "source": [
        "# Train MILES mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpwwksbL4mFM"
      },
      "outputs": [],
      "source": [
        "from mil.bag_representation.mapping import MILESMapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF8pG4vR4mFM"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer()\n",
        "\n",
        "metrics = [AUC, BinaryAccuracy]\n",
        "model = SVC(kernel='linear', C=1, class_weight='balanced')\n",
        "pipeline = [('disc_mapping', MILESMapping())]\n",
        "\n",
        "trainer.prepare(model, preprocess_pipeline=pipeline ,metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgPIBUj94mFM",
        "outputId": "bf9bfcc1-4c40-462e-f523-d5a6cf7bdb67"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 10.6 GiB for an array with shape (86631, 16384) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32mc:\\A\\breastCancer\\mil\\mil_code\\2_train_bags.ipynb 셀 54\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/A/breastCancer/mil/mil_code/2_train_bags.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m valid \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/A/breastCancer/mil/mil_code/2_train_bags.ipynb#Y110sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mfit(bags_train_1D, y_train, validation_strategy\u001b[39m=\u001b[39;49mvalid, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\mil\\trainer\\trainer.py:124\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, X_train, y_train, X_val, y_val, groups, validation_strategy, sample_weights, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics_val\u001b[39m.\u001b[39mreset_states()\n\u001b[0;32m    123\u001b[0m \u001b[39m# eval splits\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__eval_training_data(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__eval_validation_data(X_val, y_val)\n\u001b[0;32m    127\u001b[0m \u001b[39m# update progress bar\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\mil\\trainer\\trainer.py:157\u001b[0m, in \u001b[0;36mTrainer.__eval_training_data\u001b[1;34m(self, X_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m sample_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__define_sample_weights(y_train)\n\u001b[0;32m    156\u001b[0m \u001b[39m# fitting pipeline\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline\u001b[39m.\u001b[39;49mfit(X_train, y_train, model__sample_weight\u001b[39m=\u001b[39;49msample_weights, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    158\u001b[0m y_pred_train \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[0;32m    159\u001b[0m \u001b[39m# update metrics\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\sklearn\\pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \n\u001b[0;32m    354\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 378\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\sklearn\\pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    334\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[0;32m    335\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    337\u001b[0m     cloned_transformer,\n\u001b[0;32m    338\u001b[0m     X,\n\u001b[0;32m    339\u001b[0m     y,\n\u001b[0;32m    340\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    341\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    342\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[0;32m    343\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[0;32m    344\u001b[0m )\n\u001b[0;32m    345\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\sklearn\\pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    869\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 870\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[0;32m    871\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\sklearn\\base.py:870\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39;49mtransform(X)\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\mil\\bag_representation\\mapping.py:52\u001b[0m, in \u001b[0;36mMILESBase.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m\"\"\" Get the bag representation calculating the bag-instance similarity.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_exceptions(X)\n\u001b[1;32m---> 52\u001b[0m dist \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_bag_instances_distance(bag) \u001b[39mfor\u001b[39;00m bag \u001b[39min\u001b[39;00m X]\n\u001b[0;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity_measure(dist)\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\mil\\bag_representation\\mapping.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m\"\"\" Get the bag representation calculating the bag-instance similarity.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \n\u001b[0;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_exceptions(X)\n\u001b[1;32m---> 52\u001b[0m dist \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_bag_instances_distance(bag) \u001b[39mfor\u001b[39;00m bag \u001b[39min\u001b[39;00m X]\n\u001b[0;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msimilarity_measure(dist)\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\mil\\bag_representation\\mapping.py:100\u001b[0m, in \u001b[0;36mMILESBase.get_bag_instances_distance\u001b[1;34m(self, bag)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bag_instances_distance\u001b[39m(\u001b[39mself\u001b[39m, bag):\n\u001b[0;32m     88\u001b[0m     \u001b[39m\"\"\" Calculates the minimum instances between the instances \u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m        of bag and the training instances\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     d \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_instance_instances_distance(ins) \u001b[39mfor\u001b[39;00m ins \u001b[39min\u001b[39;00m bag]\n\u001b[0;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmin(d, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\mil\\bag_representation\\mapping.py:100\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_bag_instances_distance\u001b[39m(\u001b[39mself\u001b[39m, bag):\n\u001b[0;32m     88\u001b[0m     \u001b[39m\"\"\" Calculates the minimum instances between the instances \u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m        of bag and the training instances\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     d \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_instance_instances_distance(ins) \u001b[39mfor\u001b[39;00m ins \u001b[39min\u001b[39;00m bag]\n\u001b[0;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmin(d, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\mil\\bag_representation\\mapping.py:85\u001b[0m, in \u001b[0;36mMILESBase.get_instance_instances_distance\u001b[1;34m(self, instance)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m\"\"\" Calculates the distance between instance, and the instance pool.\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m axes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39marray(instance)\u001b[39m.\u001b[39mshape) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)])\n\u001b[1;32m---> 85\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(instance \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miip_, axis\u001b[39m=\u001b[39;49maxes)\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\wew12\\Anaconda3\\envs\\pytorch110_p38\\lib\\site-packages\\numpy\\linalg\\linalg.py:2556\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2553\u001b[0m     \u001b[39mreturn\u001b[39;00m add\u001b[39m.\u001b[39mreduce(\u001b[39mabs\u001b[39m(x), axis\u001b[39m=\u001b[39maxis, keepdims\u001b[39m=\u001b[39mkeepdims)\n\u001b[0;32m   2554\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mord\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mord\u001b[39m \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   2555\u001b[0m     \u001b[39m# special case for speedup\u001b[39;00m\n\u001b[1;32m-> 2556\u001b[0m     s \u001b[39m=\u001b[39m (x\u001b[39m.\u001b[39;49mconj() \u001b[39m*\u001b[39;49m x)\u001b[39m.\u001b[39mreal\n\u001b[0;32m   2557\u001b[0m     \u001b[39mreturn\u001b[39;00m sqrt(add\u001b[39m.\u001b[39mreduce(s, axis\u001b[39m=\u001b[39maxis, keepdims\u001b[39m=\u001b[39mkeepdims))\n\u001b[0;32m   2558\u001b[0m \u001b[39m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[0;32m   2559\u001b[0m \u001b[39m# are valid for vectors\u001b[39;00m\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 10.6 GiB for an array with shape (86631, 16384) and data type float64"
          ]
        }
      ],
      "source": [
        "valid = KFold(n_splits=2, shuffle=True)\n",
        "\n",
        "history = trainer.fit(bags_train_1D, y_train, validation_strategy=valid, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdpyfZzs4mFM",
        "outputId": "c818b831-1d29-4d97-d7c0-7011b9394b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7575\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'auc': 0.7439561, 'binaryaccuracy': 0.77},\n",
              " {'auc': 0.7005208, 'binaryaccuracy': 0.745}]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(np.mean([e['binaryaccuracy'] for e in history['metrics_val']]))\n",
        "history['metrics_val']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_ger2N64mFM"
      },
      "outputs": [],
      "source": [
        "model.save(r'C:\\A\\breastCancer\\mil\\output/model_MILEMapping_1.h5')\n",
        "\n",
        "import pickle\n",
        "with open(r'C:\\A\\breastCancer\\mil\\output/history_MILEMapping_1.pickle','wb') as f:\n",
        "    pickle.dump(history,f,pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NcKtCje4mFM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('pytorch112_p38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "58d57aa79b850236b521150a1202e790a96ac8259ac3baa83cc74f3e58246589"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}